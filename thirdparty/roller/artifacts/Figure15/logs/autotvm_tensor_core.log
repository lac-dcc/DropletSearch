65536 1024 4096 /home/shanbinke/TiledCompiler/tiled-compiler/microbenchmark/tvm/autotvm/tensor_core
dense_large_batch.gpu
ConfigSpace (len=29099070, space_map=
   0 tile_x: Split(policy=factors, product=65536, num_outputs=4) len=969
   1 tile_y: Split(policy=factors, product=4096, num_outputs=4) len=455
   2 tile_k: Split(policy=factors, product=1024, num_outputs=3) len=66
)
Finish loading 2000 records
Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -thread_warp_size=32, workload=('dense_large_batch.gpu', ('TENSOR', (65536, 1024), 'float32'), ('TENSOR', (1024, 4096), 'float32')). A fallback configuration is used, which may bring great performance regression.
/home/shanbinke/TiledCompiler/tiled-compiler/microbenchmark/tvm/autotvm/tensor_core/matmul_65536_1024_4096.log

Best config:
,None
best runtime:  2.0314565
compilation time:  8507.336164951324
65536 1024 1024 /home/shanbinke/TiledCompiler/tiled-compiler/microbenchmark/tvm/autotvm/tensor_core
dense_large_batch.gpu
ConfigSpace (len=18290844, space_map=
   0 tile_x: Split(policy=factors, product=65536, num_outputs=4) len=969
   1 tile_y: Split(policy=factors, product=1024, num_outputs=4) len=286
   2 tile_k: Split(policy=factors, product=1024, num_outputs=3) len=66
)
Finish loading 2000 records
Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -thread_warp_size=32, workload=('dense_large_batch.gpu', ('TENSOR', (65536, 1024), 'float32'), ('TENSOR', (1024, 1024), 'float32')). A fallback configuration is used, which may bring great performance regression.
/home/shanbinke/TiledCompiler/tiled-compiler/microbenchmark/tvm/autotvm/tensor_core/matmul_65536_1024_1024.log

Best config:
,None
best runtime:  2.129103098039216
compilation time:  8401.869921445847
65536 4096 1024 /home/shanbinke/TiledCompiler/tiled-compiler/microbenchmark/tvm/autotvm/tensor_core
dense_large_batch.gpu
ConfigSpace (len=25219194, space_map=
   0 tile_x: Split(policy=factors, product=65536, num_outputs=4) len=969
   1 tile_y: Split(policy=factors, product=1024, num_outputs=4) len=286
   2 tile_k: Split(policy=factors, product=4096, num_outputs=3) len=91
)
Finish loading 2000 records
Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -thread_warp_size=32, workload=('dense_large_batch.gpu', ('TENSOR', (65536, 4096), 'float32'), ('TENSOR', (4096, 1024), 'float32')). A fallback configuration is used, which may bring great performance regression.
/home/shanbinke/TiledCompiler/tiled-compiler/microbenchmark/tvm/autotvm/tensor_core/matmul_65536_4096_1024.log

Best config:
,None
best runtime:  inf
compilation time:  52.19712734222412
65536 16384 1024 /home/shanbinke/TiledCompiler/tiled-compiler/microbenchmark/tvm/autotvm/tensor_core
dense_large_batch.gpu
ConfigSpace (len=33256080, space_map=
   0 tile_x: Split(policy=factors, product=65536, num_outputs=4) len=969
   1 tile_y: Split(policy=factors, product=1024, num_outputs=4) len=286
   2 tile_k: Split(policy=factors, product=16384, num_outputs=3) len=120
)
Finish loading 2000 records
Cannot find config for target=cuda -keys=cuda,gpu -max_num_threads=1024 -thread_warp_size=32, workload=('dense_large_batch.gpu', ('TENSOR', (65536, 16384), 'float32'), ('TENSOR', (16384, 1024), 'float32')). A fallback configuration is used, which may bring great performance regression.
/home/shanbinke/TiledCompiler/tiled-compiler/microbenchmark/tvm/autotvm/tensor_core/matmul_65536_16384_1024.log

Best config:
,None
best runtime:  inf
compilation time:  49.93211770057678
