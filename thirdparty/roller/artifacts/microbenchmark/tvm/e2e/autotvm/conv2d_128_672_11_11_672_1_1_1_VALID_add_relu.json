{"parameters": {"input_shape": [128, 672, 11, 11], "filter_shape": [672, 672, 1, 1], "output_shape": [128, 672, 11, 11], "window_movement_strides": [1, 1], "padding_below_diff": [0, 0], "window_dilation_strides": [1, 1]}, "op_type": "Fused_Convolution_Add_Relu", "tvm_func_name": "conv2d_128_672_11_11_672_1_1_1_VALID_add_relu", "code": "extern \"C\" __global__ void conv2d_128_672_11_11_672_1_1_1_VALID_add_relu(float* __restrict__ placeholder, float* __restrict__ placeholder1, float* __restrict__ compute, float* __restrict__ input2) {\n  float compute1[42];\n  __shared__ float pad_temp_shared[847];\n  __shared__ float placeholder_shared[294];\n  #pragma unroll\n  for (int ff_init = 0; ff_init < 2; ++ff_init) {\n    #pragma unroll\n    for (int vthread_s = 0; vthread_s < 21; ++vthread_s) {\n      compute1[(((vthread_s * 2) + ff_init))] = 0.000000e+00f;\n    }\n  }\n  for (int rc_outer = 0; rc_outer < 96; ++rc_outer) {\n    __syncthreads();\n    #pragma unroll\n    for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner < 7; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner) {\n      pad_temp_shared[((((((int)threadIdx.y) * 77) + (((int)threadIdx.x) * 7)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner))] = placeholder[(((((((((int)blockIdx.z) >> 4) * 81312) + (rc_outer * 847)) + (((int)threadIdx.y) * 77)) + (((int)threadIdx.x) * 7)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner))];\n    }\n    #pragma unroll\n    for (int ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1 = 0; ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1 < 3; ++ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) {\n      if ((((((int)threadIdx.y) * 27) + (((int)threadIdx.x) * 3)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) < 294) {\n        if (((((int)threadIdx.x) * 3) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) < 27) {\n          placeholder_shared[((((((int)threadIdx.y) * 27) + (((int)threadIdx.x) * 3)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1))] = placeholder1[((((((((int)blockIdx.z) & 15) * 28224) + (((((((int)threadIdx.y) * 27) + (((int)threadIdx.x) * 3)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) / 7) * 672)) + (rc_outer * 7)) + ((((((int)threadIdx.y) * 27) + (((int)threadIdx.x) * 3)) + ax0_ax1_fused_ax2_fused_ax3_fused_inner_inner_inner1) % 7)))];\n        }\n      }\n    }\n    __syncthreads();\n    #pragma unroll\n    for (int rc_inner = 0; rc_inner < 7; ++rc_inner) {\n      #pragma unroll\n      for (int ff = 0; ff < 2; ++ff) {\n        #pragma unroll\n        for (int vthread_s1 = 0; vthread_s1 < 21; ++vthread_s1) {\n          compute1[(((vthread_s1 * 2) + ff))] = (compute1[(((vthread_s1 * 2) + ff))] + (pad_temp_shared[((((rc_inner * 121) + (((int)threadIdx.y) * 11)) + ((int)threadIdx.x)))] * placeholder_shared[((((vthread_s1 * 14) + (ff * 7)) + rc_inner))]));\n        }\n      }\n    }\n  }\n  #pragma unroll\n  for (int i1_inner_inner_inner = 0; i1_inner_inner_inner < 2; ++i1_inner_inner_inner) {\n    #pragma unroll\n    for (int vthread_s2 = 0; vthread_s2 < 21; ++vthread_s2) {\n      compute[((((((((int)blockIdx.z) * 5082) + (vthread_s2 * 242)) + (i1_inner_inner_inner * 121)) + (((int)threadIdx.y) * 11)) + ((int)threadIdx.x)))] = max((compute1[(((vthread_s2 * 2) + i1_inner_inner_inner))] + input2[((((((((int)blockIdx.z) * 5082) + (vthread_s2 * 242)) + (i1_inner_inner_inner * 121)) + (((int)threadIdx.y) * 11)) + ((int)threadIdx.x)))]), 0.000000e+00f);\n    }\n  }\n}\n", "gridDim": [1, 1, 2048], "blockDim": [11, 11, 1]}