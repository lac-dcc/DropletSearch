{"parameters": {"input_shape": [128, 84, 83, 83], "filter_shape": [84, 1, 7, 7], "output_shape": [128, 84, 42, 42], "window_movement_strides": [2, 2], "padding_below_diff": [3, 3], "window_dilation_strides": [1, 1]}, "op_type": "DepthwiseConv2dNative", "tvm_func_name": "roller_DepthwiseConv2dNative__128_84_83_83___7_7_84_1___128_84_42_42_", "code": "extern \"C\" __global__ void roller_DepthwiseConv2dNative__128_84_83_83___7_7_84_1___128_84_42_42_(float* __restrict__ data, float* __restrict__ kernel, float* __restrict__ compute) {\n  float DepthwiseConv2d_local[1];\n  __shared__ float PaddedInput_shared[1513];\n  __shared__ float compute_shared[49];\n  float PaddedInput_shared_local[1];\n  float compute_shared_local[1];\n  DepthwiseConv2d_local[(0)] = 0.000000e+00f;\n  PaddedInput_shared[(((int)threadIdx.x))] = ((((3 <= (((((int)blockIdx.x) % 7) * 12) + (((int)threadIdx.x) / 89))) && (3 <= (((int)threadIdx.x) % 89))) && ((((int)threadIdx.x) % 89) < 86)) ? data[(((((((((int)blockIdx.x) / 7) * 6889) + ((((int)blockIdx.x) % 7) * 996)) + ((((int)threadIdx.x) / 89) * 83)) + (((int)threadIdx.x) % 89)) - 252))] : 0.000000e+00f);\n  PaddedInput_shared[((((int)threadIdx.x) + 288))] = (((3 <= ((((int)threadIdx.x) + 21) % 89)) && (((((int)threadIdx.x) + 21) % 89) < 86)) ? data[(((((((((int)blockIdx.x) / 7) * 6889) + ((((int)blockIdx.x) % 7) * 996)) + (((((int)threadIdx.x) + 288) / 89) * 83)) + ((((int)threadIdx.x) + 21) % 89)) - 252))] : 0.000000e+00f);\n  PaddedInput_shared[((((int)threadIdx.x) + 576))] = (((3 <= ((((int)threadIdx.x) + 42) % 89)) && (((((int)threadIdx.x) + 42) % 89) < 86)) ? data[(((((((((int)blockIdx.x) / 7) * 6889) + ((((int)blockIdx.x) % 7) * 996)) + (((((int)threadIdx.x) + 576) / 89) * 83)) + ((((int)threadIdx.x) + 42) % 89)) - 252))] : 0.000000e+00f);\n  PaddedInput_shared[((((int)threadIdx.x) + 864))] = (((3 <= ((((int)threadIdx.x) + 63) % 89)) && (((((int)threadIdx.x) + 63) % 89) < 86)) ? data[(((((((((int)blockIdx.x) / 7) * 6889) + ((((int)blockIdx.x) % 7) * 996)) + (((((int)threadIdx.x) + 864) / 89) * 83)) + ((((int)threadIdx.x) + 63) % 89)) - 252))] : 0.000000e+00f);\n  PaddedInput_shared[((((int)threadIdx.x) + 1152))] = (((((((((int)blockIdx.x) % 7) * 12) + ((((int)threadIdx.x) + 1152) / 89)) < 86) && (3 <= ((((int)threadIdx.x) + 84) % 89))) && (((((int)threadIdx.x) + 84) % 89) < 86)) ? data[(((((((((int)blockIdx.x) / 7) * 6889) + ((((int)blockIdx.x) % 7) * 996)) + (((((int)threadIdx.x) + 1152) / 89) * 83)) + ((((int)threadIdx.x) + 84) % 89)) - 252))] : 0.000000e+00f);\n  if (((int)threadIdx.x) < 73) {\n    PaddedInput_shared[((((int)threadIdx.x) + 1440))] = ((((((((int)blockIdx.x) % 7) * 12) + ((((int)threadIdx.x) + 1440) / 89)) < 86) && (((int)threadIdx.x) < 70)) ? data[(((((((((int)blockIdx.x) / 7) * 6889) + ((((int)blockIdx.x) % 7) * 996)) + (((((int)threadIdx.x) + 1440) / 89) * 83)) + (((int)threadIdx.x) + 16)) - 252))] : 0.000000e+00f);\n  }\n  if (((int)threadIdx.x) < 49) {\n    compute_shared[(((int)threadIdx.x))] = kernel[(((((((int)blockIdx.x) % 588) / 7) * 49) + ((int)threadIdx.x)))];\n  }\n  __syncthreads();\n  for (int k_inner_outer = 0; k_inner_outer < 49; ++k_inner_outer) {\n    if ((((((int)threadIdx.x) % 48) * 2) + (k_inner_outer % 7)) < 89) {\n      PaddedInput_shared_local[(0)] = PaddedInput_shared[((((((((int)threadIdx.x) / 48) * 178) + ((k_inner_outer / 7) * 89)) + ((((int)threadIdx.x) % 48) * 2)) + (k_inner_outer % 7)))];\n    }\n    compute_shared_local[(0)] = compute_shared[(k_inner_outer)];\n    if ((((int)threadIdx.x) % 48) < 42) {\n      DepthwiseConv2d_local[(0)] = (DepthwiseConv2d_local[(0)] + (PaddedInput_shared_local[(0)] * compute_shared_local[(0)]));\n    }\n  }\n  if ((((int)threadIdx.x) % 48) < 42) {\n    compute[((((((int)blockIdx.x) * 252) + ((((int)threadIdx.x) / 48) * 42)) + (((int)threadIdx.x) % 48)))] = DepthwiseConv2d_local[(0)];\n  }\n}\n", "gridDim": [75264, 1, 1], "blockDim": [288, 1, 1]}