{"parameters": {"input_shape": [128, 672, 21, 21], "filter_shape": [672, 1, 7, 7], "output_shape": [128, 672, 11, 11], "window_movement_strides": [2, 2], "padding_below_diff": [3, 3], "window_dilation_strides": [1, 1]}, "op_type": "DepthwiseConv2dNative", "tvm_func_name": "roller_DepthwiseConv2dNative__128_672_21_21___7_7_672_1___128_672_11_11_", "code": "extern \"C\" __global__ void roller_DepthwiseConv2dNative__128_672_21_21___7_7_672_1___128_672_11_11_(float* __restrict__ data, float* __restrict__ kernel, float* __restrict__ compute) {\n  float DepthwiseConv2d_local[1];\n  __shared__ float PaddedInput_shared[1458];\n  __shared__ float compute_shared[98];\n  float PaddedInput_shared_local[1];\n  float compute_shared_local[1];\n  DepthwiseConv2d_local[(0)] = 0.000000e+00f;\n  PaddedInput_shared[(((int)threadIdx.x))] = ((((81 <= ((int)threadIdx.x)) && (3 <= (((int)threadIdx.x) % 27))) && ((((int)threadIdx.x) % 27) < 24)) ? data[(((((((int)blockIdx.x) * 882) + ((((int)threadIdx.x) / 27) * 21)) + (((int)threadIdx.x) % 27)) - 66))] : 0.000000e+00f);\n  PaddedInput_shared[((((int)threadIdx.x) + 352))] = ((((((int)threadIdx.x) < 296) && (3 <= ((((int)threadIdx.x) + 1) % 27))) && (((((int)threadIdx.x) + 1) % 27) < 24)) ? data[(((((((int)blockIdx.x) * 882) + (((((int)threadIdx.x) + 352) / 27) * 21)) + ((((int)threadIdx.x) + 1) % 27)) - 66))] : 0.000000e+00f);\n  PaddedInput_shared[((((int)threadIdx.x) + 704))] = (((((81 <= ((((int)threadIdx.x) + 704) % 729)) && (((((int)threadIdx.x) + 704) % 729) < 648)) && (3 <= ((((int)threadIdx.x) + 2) % 27))) && (((((int)threadIdx.x) + 2) % 27) < 24)) ? data[((((((((int)blockIdx.x) * 882) + (((((int)threadIdx.x) + 704) / 729) * 441)) + ((((((int)threadIdx.x) + 704) % 729) / 27) * 21)) + ((((int)threadIdx.x) + 2) % 27)) - 66))] : 0.000000e+00f);\n  PaddedInput_shared[((((int)threadIdx.x) + 1056))] = ((((((int)threadIdx.x) < 321) && (3 <= ((((int)threadIdx.x) + 3) % 27))) && (((((int)threadIdx.x) + 3) % 27) < 24)) ? data[((((((((int)blockIdx.x) * 882) + (((((int)threadIdx.x) + 1056) / 729) * 441)) + (((((int)threadIdx.x) + 327) / 27) * 21)) + ((((int)threadIdx.x) + 3) % 27)) - 66))] : 0.000000e+00f);\n  if (((int)threadIdx.x) < 50) {\n    PaddedInput_shared[((((int)threadIdx.x) + 1408))] = 0.000000e+00f;\n  }\n  if (((int)threadIdx.x) < 98) {\n    compute_shared[(((int)threadIdx.x))] = kernel[((((((int)blockIdx.x) % 336) * 98) + ((int)threadIdx.x)))];\n  }\n  __syncthreads();\n  for (int k_inner_outer = 0; k_inner_outer < 49; ++k_inner_outer) {\n    if ((((((int)threadIdx.x) & 15) * 2) + (k_inner_outer % 7)) < 27) {\n      PaddedInput_shared_local[(0)] = PaddedInput_shared[(((((((((int)threadIdx.x) / 176) * 729) + (((((int)threadIdx.x) % 176) >> 4) * 54)) + ((k_inner_outer / 7) * 27)) + ((((int)threadIdx.x) & 15) * 2)) + (k_inner_outer % 7)))];\n    }\n    compute_shared_local[(0)] = compute_shared[((((((int)threadIdx.x) / 176) * 49) + k_inner_outer))];\n    if ((((int)threadIdx.x) & 15) < 11) {\n      DepthwiseConv2d_local[(0)] = (DepthwiseConv2d_local[(0)] + (PaddedInput_shared_local[(0)] * compute_shared_local[(0)]));\n    }\n  }\n  if ((((int)threadIdx.x) & 15) < 11) {\n    compute[((((((int)blockIdx.x) * 242) + ((((int)threadIdx.x) >> 4) * 11)) + (((int)threadIdx.x) & 15)))] = DepthwiseConv2d_local[(0)];\n  }\n}\n", "gridDim": [43008, 1, 1], "blockDim": [352, 1, 1]}