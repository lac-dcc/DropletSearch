{"parameters": {"input_shape": [128, 336, 45, 45], "filter_shape": [336, 1, 5, 5], "output_shape": [128, 336, 21, 21], "window_movement_strides": [2, 2], "padding_below_diff": [0, 0], "window_dilation_strides": [1, 1]}, "op_type": "DepthwiseConv2dNative", "tvm_func_name": "roller_DepthwiseConv2dNative__128_336_45_45___5_5_336_1___128_336_21_21_", "code": "extern \"C\" __global__ void roller_DepthwiseConv2dNative__128_336_45_45___5_5_336_1___128_336_21_21_(float* __restrict__ data, float* __restrict__ kernel, float* __restrict__ compute) {\n  float DepthwiseConv2d_local[1];\n  __shared__ float PaddedInput_shared[1620];\n  __shared__ float compute_shared[100];\n  float PaddedInput_shared_local[1];\n  float compute_shared_local[1];\n  DepthwiseConv2d_local[(0)] = 0.000000e+00f;\n  PaddedInput_shared[(((int)threadIdx.x))] = data[(((((((int)blockIdx.x) / 7) * 8100) + ((((int)blockIdx.x) % 7) * 270)) + ((int)threadIdx.x)))];\n  PaddedInput_shared[((((int)threadIdx.x) + 288))] = data[((((((((int)blockIdx.x) / 7) * 8100) + (((((int)threadIdx.x) + 288) / 405) * 2025)) + ((((int)blockIdx.x) % 7) * 270)) + ((((int)threadIdx.x) + 288) % 405)))];\n  PaddedInput_shared[((((int)threadIdx.x) + 576))] = data[((((((((int)blockIdx.x) / 7) * 8100) + (((((int)threadIdx.x) + 576) / 405) * 2025)) + ((((int)blockIdx.x) % 7) * 270)) + ((((int)threadIdx.x) + 171) % 405)))];\n  PaddedInput_shared[((((int)threadIdx.x) + 864))] = data[((((((((int)blockIdx.x) / 7) * 8100) + (((((int)threadIdx.x) + 864) / 405) * 2025)) + ((((int)blockIdx.x) % 7) * 270)) + (((int)threadIdx.x) + 54)))];\n  PaddedInput_shared[((((int)threadIdx.x) + 1152))] = data[((((((((int)blockIdx.x) / 7) * 8100) + (((((int)threadIdx.x) + 1152) / 405) * 2025)) + ((((int)blockIdx.x) % 7) * 270)) + ((((int)threadIdx.x) + 342) % 405)))];\n  if (((int)threadIdx.x) < 180) {\n    PaddedInput_shared[((((int)threadIdx.x) + 1440))] = data[((((((((int)blockIdx.x) / 7) * 8100) + (((((int)threadIdx.x) + 1440) / 405) * 2025)) + ((((int)blockIdx.x) % 7) * 270)) + (((int)threadIdx.x) + 225)))];\n  }\n  if (((int)threadIdx.x) < 100) {\n    compute_shared[(((int)threadIdx.x))] = kernel[(((((((int)blockIdx.x) % 588) / 7) * 100) + ((int)threadIdx.x)))];\n  }\n  __syncthreads();\n  for (int k_inner_outer = 0; k_inner_outer < 25; ++k_inner_outer) {\n    if ((((((int)threadIdx.x) % 24) * 2) + (k_inner_outer % 5)) < 45) {\n      PaddedInput_shared_local[(0)] = PaddedInput_shared[(((((((((int)threadIdx.x) / 72) * 405) + (((((int)threadIdx.x) % 72) / 24) * 90)) + ((k_inner_outer / 5) * 45)) + ((((int)threadIdx.x) % 24) * 2)) + (k_inner_outer % 5)))];\n    }\n    compute_shared_local[(0)] = compute_shared[((((((int)threadIdx.x) / 72) * 25) + k_inner_outer))];\n    if ((((int)threadIdx.x) % 24) < 21) {\n      DepthwiseConv2d_local[(0)] = (DepthwiseConv2d_local[(0)] + (PaddedInput_shared_local[(0)] * compute_shared_local[(0)]));\n    }\n  }\n  if ((((int)threadIdx.x) % 24) < 21) {\n    compute[(((((((((int)blockIdx.x) / 7) * 1764) + ((((int)threadIdx.x) / 72) * 441)) + ((((int)blockIdx.x) % 7) * 63)) + (((((int)threadIdx.x) % 72) / 24) * 21)) + (((int)threadIdx.x) % 24)))] = DepthwiseConv2d_local[(0)];\n  }\n}\n", "gridDim": [75264, 1, 1], "blockDim": [288, 1, 1]}